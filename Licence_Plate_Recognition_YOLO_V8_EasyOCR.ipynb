{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI3lrkLBcV-o",
        "outputId": "fdf0951d-fa0c-4d31-ab46-ce8eeb77805d"
      },
      "outputs": [],
      "source": [
        "cd /content/Licence-Plate-Detection-and-Recognition-using-YOLO-V8-EasyOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SAy_5DdlcPaG",
        "outputId": "289873f9-87ad-4bc6-f1c8-20dd1fc1b0c4"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUhBdfQ-cbzV",
        "outputId": "2e0c445a-2079-4f2e-8b70-8535e54ab343"
      },
      "outputs": [],
      "source": [
        "! python predictWithOCR.py model='best.pt' source='demo.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openvino\n",
        "\n",
        "import hydra\n",
        "import torch\n",
        "import easyocr\n",
        "import cv2\n",
        "from ultralytics.yolo.engine.predictor import BasePredictor\n",
        "from ultralytics.yolo.utils import DEFAULT_CONFIG, ROOT, ops\n",
        "from ultralytics.yolo.utils.checks import check_imgsz\n",
        "from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box\n",
        "\n",
        "def getOCR(im, coors):\n",
        "    x,y,w, h = int(coors[0]), int(coors[1]), int(coors[2]),int(coors[3])\n",
        "    im = im[y:h,x:w]\n",
        "    conf = 0.2\n",
        "\n",
        "    gray = cv2.cvtColor(im , cv2.COLOR_RGB2GRAY)\n",
        "    results = reader.readtext(gray)\n",
        "    ocr = \"\"\n",
        "\n",
        "    for result in results:\n",
        "        if len(results) == 1:\n",
        "            ocr = result[1]\n",
        "        if len(results) >1 and len(results[1])>6 and results[2]> conf:\n",
        "            ocr = result[1]\n",
        "    \n",
        "    return str(ocr)\n",
        "\n",
        "class DetectionPredictor(BasePredictor):\n",
        "\n",
        "    def get_annotator(self, img):\n",
        "        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))\n",
        "\n",
        "    def preprocess(self, img):\n",
        "        img = torch.from_numpy(img).to(self.model.device)\n",
        "        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32\n",
        "        img /= 255  # 0 - 255 to 0.0 - 1.0\n",
        "        return img\n",
        "\n",
        "    def postprocess(self, preds, img, orig_img):\n",
        "        preds = ops.non_max_suppression(preds,\n",
        "                                        self.args.conf,\n",
        "                                        self.args.iou,\n",
        "                                        agnostic=self.args.agnostic_nms,\n",
        "                                        max_det=self.args.max_det)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            shape = orig_img[i].shape if self.webcam else orig_img.shape\n",
        "            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def write_results(self, idx, preds, batch):\n",
        "        p, im, im0 = batch\n",
        "        log_string = \"\"\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]  # expand for batch dim\n",
        "        self.seen += 1\n",
        "        im0 = im0.copy()\n",
        "        if self.webcam:  # batch_size >= 1\n",
        "            log_string += f'{idx}: '\n",
        "            frame = self.dataset.count\n",
        "        else:\n",
        "            frame = getattr(self.dataset, 'frame', 0)\n",
        "\n",
        "        self.data_path = p\n",
        "        # save_path = str(self.save_dir / p.name)  # im.jpg\n",
        "        self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}')\n",
        "        log_string += '%gx%g ' % im.shape[2:]  # print string\n",
        "        self.annotator = self.get_annotator(im0)\n",
        "\n",
        "        det = preds[idx]\n",
        "        self.all_outputs.append(det)\n",
        "        if len(det) == 0:\n",
        "            return log_string\n",
        "        for c in det[:, 5].unique():\n",
        "            n = (det[:, 5] == c).sum()  # detections per class\n",
        "            log_string += f\"{n} {self.model.names[int(c)]}{'s' * (n > 1)}, \"\n",
        "        # write\n",
        "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "        for *xyxy, conf, cls in reversed(det):\n",
        "            if self.args.save_txt:  # Write to file\n",
        "                xywh = (ops.xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                line = (cls, *xywh, conf) if self.args.save_conf else (cls, *xywh)  # label format\n",
        "                with open(f'{self.txt_path}.txt', 'a') as f:\n",
        "                    f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "            if self.args.save or self.args.save_crop or self.args.show:  # Add bbox to image\n",
        "                c = int(cls)  # integer class\n",
        "                label = None if self.args.hide_labels else (\n",
        "                    self.model.names[c] if self.args.hide_conf else f'{self.model.names[c]} {conf:.2f}')\n",
        "                ocr = getOCR(im0,xyxy)\n",
        "                if ocr != \"\":\n",
        "                    label = ocr\n",
        "                self.annotator.box_label(xyxy, label, color=colors(c, True))\n",
        "            if self.args.save_crop:\n",
        "                imc = im0.copy()\n",
        "                save_one_box(xyxy,\n",
        "                             imc,\n",
        "                             file=self.save_dir / 'crops' / self.model.model.names[c] / f'{self.data_path.stem}.jpg',\n",
        "                             BGR=True)\n",
        "\n",
        "        return log_string\n",
        "\n",
        "\n",
        "@hydra.main(version_base=None, config_path=str(DEFAULT_CONFIG.parent), config_name=DEFAULT_CONFIG.name)\n",
        "def predict(cfg):\n",
        "    cfg.model = cfg.model or \"yolov8n.pt\"\n",
        "    cfg.imgsz = check_imgsz(cfg.imgsz, min_dim=2)  # check image size\n",
        "    cfg.source = cfg.source if cfg.source is not None else ROOT / \"assets\"\n",
        "    predictor = DetectionPredictor(cfg)\n",
        "    predictor()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    predict()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
